import numpy as np
import os
from collections import defaultdict
from matplotlib.image import imread
from skimage.transform import resize
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, pairwise_kernels
from sklearn.model_selection import LeaveOneOut
from sklearn.preprocessing import StandardScaler
from scipy.spatial.distance import cdist

def npz(image_dir, output_file, shape=(28, 28)):
    image_vectors, ids = [], []
    for fname in sorted(os.listdir(image_dir)):
        if fname.lower().endswith(".pgm"):
            person_id = int(fname[:2])
            image = imread(os.path.join(image_dir, fname))
            image = resize(image, shape, anti_aliasing=True)
            image_vectors.append(image.flatten())
            ids.append(person_id)

    image_vectors = np.array(image_vectors)
    ids = np.array(ids)
    np.savez(output_file, images=image_vectors, labels=ids)

def load_cache(npz_path):
    data = np.load(npz_path)
    return data["images"], data["labels"]

def gaussian_noise(images, mean=0.0, std=0.1):
    noisy_images = []
    for img in images:
        noise = np.random.normal(mean, std, img.shape)
        noisy = img + noise * 255
        noisy = np.clip(noisy, 0, 255)
        noisy_images.append(noisy.astype(np.uint8))
    return np.array(noisy_images)

def rbf(X, gamma):
    return np.exp(-gamma * cdist(X, X, metric='sqeuclidean'))

def polynomial(X, degree, alpha=1.0, r=1.0):
    return (alpha * (X @ X.T) + r) ** degree

def center_kernel(K):
    n = K.shape[0]
    ones = np.ones((n, n)) / n
    return K - ones @ K - K @ ones + ones @ K @ ones

def kernel_pca(X_train, kernel, degree=None, gamma=None, alpha=1.0, r=1.0, variance_threshold=0.90):
    if kernel == 'rbf':
        K = rbf(X_train, gamma)
    elif kernel == 'polynomial':
        K = polynomial(X_train, degree=degree, alpha=alpha, r=r)
    else:
        return None

    K_centered = center_kernel(K)
    eigenvalues, eigenvectors = np.linalg.eigh(K_centered)
    idx = np.argsort(eigenvalues)[::-1]
    eigenvalues, eigenvectors = eigenvalues[idx], eigenvectors[:, idx]

    positive = eigenvalues > 1e-10
    eigenvalues, eigenvectors = eigenvalues[positive], eigenvectors[:, positive]

    var_ratio = eigenvalues / np.sum(eigenvalues)
    cumulative = np.cumsum(var_ratio)
    n_components = np.searchsorted(cumulative, variance_threshold) + 1
    top_eigenvalues = eigenvalues[:n_components]
    top_eigenvectors = eigenvectors[:, :n_components]
    norm_eigenvectors = top_eigenvectors / np.sqrt(top_eigenvalues)

    return K_centered, norm_eigenvectors, top_eigenvalues

def project(X_train, x_test, kernel, degree=None, gamma=None, eigenvectors=None, K_train=None, alpha=1.0, r=1.0):
    train_and_test = np.vstack([X_train, x_test.reshape(1, -1)])

    kernel_params = {}
    if kernel == 'rbf':
        kernel_params['gamma'] = gamma
    elif kernel == 'polynomial':
        kernel_params['gamma'] = alpha
        kernel_params['degree'] = degree
        kernel_params['coef0'] = r

    K_full = pairwise_kernels(train_and_test, metric=kernel, **kernel_params)

    K_mean_row = np.mean(K_full, axis=1, keepdims=True)
    K_mean_col = np.mean(K_full, axis=0, keepdims=True)
    K_mean_total = np.mean(K_full)
    K_full_centered = K_full - K_mean_row - K_mean_col + K_mean_total

    K_test_centered = K_full_centered[-1, :-1]

    return K_test_centered @ eigenvectors

def main(kernel='polynomial', degree=2, alpha=0.01, r=1.0):
    X_all, y_all = load_cache("att_28x28.npz")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_all)

    loo = LeaveOneOut()
    y_true_svm, y_pred_svm = [], []
    y_true_knn = []
    knn_preds_by_k = defaultdict(list)

    for train_idx, test_idx in loo.split(X_scaled):
        X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
        y_train, y_test = y_all[train_idx], y_all[test_idx]

        K_train, eigvecs, _ = kernel_pca(
            X_train, kernel=kernel, degree=degree, gamma=0.00153,
            alpha=alpha, r=r, variance_threshold=0.90
        )
        X_train_proj = K_train @ eigvecs

        X_test_proj = np.vstack([
            project(X_train, X_scaled[i], kernel=kernel, degree=degree, gamma=0.00153,
                    alpha=alpha, r=r, eigenvectors=eigvecs, K_train=K_train)
            for i in test_idx
        ])

        clf = SVC(kernel="linear")
        clf.fit(X_train_proj, y_train)
        pred_svm = clf.predict(X_test_proj)

        y_true_svm.append(y_test[0])
        y_pred_svm.append(pred_svm[0])

        y_true_knn.append(y_test[0])
        for k in range(1, 11):
            knn = KNeighborsClassifier(n_neighbors=k)
            knn.fit(X_train_proj, y_train)
            pred_knn = knn.predict(X_test_proj)
            knn_preds_by_k[k].append(pred_knn[0])

    acc_svm = accuracy_score(y_true_svm, y_pred_svm)
    print(f"   SVM: {acc_svm:.3f}")

    best_k, best_acc = 1, 0.0
    for k in range(1, 11):
        acc_k = accuracy_score(y_true_knn, knn_preds_by_k[k])
        if acc_k > best_acc:
            best_k = k
            best_acc = acc_k

    print(f" Best k-NN Accuracy: {best_acc:.3f} at k={best_k}")
npz = 'path/toyour/npzpath'
main()
