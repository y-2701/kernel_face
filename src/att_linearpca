from matplotlib.image import imread
import numpy as np
import os
from skimage.transform import resize

att_path = 'path/to/your/database'

filenames = sorted([f for f in os.listdir(att_path) if f.lower().endswith(".pgm")])
all_images = []
all_labels = []

for names in filenames:
    person_id = int(names[:2])
    full_path = os.path.join(att_path, names)
    image = imread(full_path)
    image_resized = resize(image, (28, 28), anti_aliasing=True)

    all_images.append(image_resized.flatten())
    all_labels.append(person_id)

all_images = np.array(all_images)
all_labels = np.array(all_labels)

correct = 0
total = len(all_images)

for i in range(total):
    test_img = all_images[i]
    test_label = all_labels[i]

    train_imgs = np.delete(all_images, i, axis=0)
    train_labels = np.delete(all_labels, i, axis=0)

    mean_face = np.mean(train_imgs, axis=0)
    train_centered = train_imgs - mean_face
    test_centered = test_img - mean_face

    cov_matrix = (train_centered @ train_centered.T) / train_centered.shape[0]
    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
    idx = np.argsort(eigenvalues)[::-1]
    eigenvectors = eigenvectors[:, idx]
    eigenfaces = train_centered.T @ eigenvectors
    eigenfaces = eigenfaces / np.linalg.norm(eigenfaces, axis=0)

    explained_variance = eigenvalues[idx] / np.sum(eigenvalues)
    cumulative_variance = np.cumsum(explained_variance)
    k = np.searchsorted(cumulative_variance, 0.95)
    eigenfaces_k = eigenfaces[:, :k + 1]

    train_proj = train_centered @ eigenfaces_k
    test_proj = test_centered @ eigenfaces_k  # (k+1,)

    diff = train_proj - test_proj
    distances = np.linalg.norm(diff, axis=1)
    nn_idx = np.argmin(distances)
    prediction = train_labels[nn_idx]

    if prediction == test_label:
        correct += 1

print(f"Leave-One-Out Accuracy with 28x28 images: {correct / total:.4f}")
